{"metadata":{"kernelspec":{"display_name":"Python [conda env:base] *","language":"python","name":"conda-base-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.7"}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"22b90812-00d9-42f9-b508-2ea533fefffa","cell_type":"code","source":"import pandas as pd\n","metadata":{"trusted":true},"outputs":[],"execution_count":15},{"id":"4e9fceb2-74cb-4870-9d03-97bbf4e036e9","cell_type":"code","source":"# Part 1: Data Exploration\n# 1. Load the dataset\ndf = pd.read_csv('Documents/customer_orders.csv')","metadata":{"trusted":true},"outputs":[],"execution_count":18},{"id":"c61cfb79-c90f-4f5e-875e-cca6ee694449","cell_type":"code","source":"# 2. Examine the data\nprint(\"First 5 rows of the dataset:\")\nprint(df.head())\n\nprint(\"\\nDataset information:\")\nprint(df.info())\n\nprint(\"\\nSummary statistics:\")\nprint(df.describe())\n","metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"First 5 rows of the dataset:\n  customer_id             name                       email   age     location  \\\n0    CUST0001       John Smith        john.smith@gmail.com  32.0     New York   \n1    CUST0002     Mary Johnson      mary.johnson@yahoo.com   NaN  Los Angeles   \n2    CUST0003  Robert Williams      r.williams@hotmail.com  45.0      Chicago   \n3    CUST0004   jennifer Brown  jennifer.brown@outlook.com  29.0          NYC   \n4    CUST0005   MICHAEL Garcia    michael.garcia@gmail.com  68.0      Houston   \n\n    join_date last_purchase_date  order_total  items_purchased  \\\n0  2023-06-15         06/20/2024        85.99              3.0   \n1  2023-08-22         09/15/2024        64.50              2.0   \n2  2022-11-30         01/22/2025       125.75              5.0   \n3  2024-01-18                NaN          NaN              NaN   \n4  2023-04-07         05/30/2024        42.99              2.0   \n\n  preferred_category  \n0        Electronics  \n1           Clothing  \n2              Books  \n3             Beauty  \n4     home & kitchen  \n\nDataset information:\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 106 entries, 0 to 105\nData columns (total 10 columns):\n #   Column              Non-Null Count  Dtype  \n---  ------              --------------  -----  \n 0   customer_id         106 non-null    object \n 1   name                106 non-null    object \n 2   email               106 non-null    object \n 3   age                 93 non-null     float64\n 4   location            106 non-null    object \n 5   join_date           106 non-null    object \n 6   last_purchase_date  98 non-null     object \n 7   order_total         98 non-null     float64\n 8   items_purchased     98 non-null     float64\n 9   preferred_category  103 non-null    object \ndtypes: float64(3), object(7)\nmemory usage: 8.4+ KB\nNone\n\nSummary statistics:\n             age  order_total  items_purchased\ncount  93.000000    98.000000        98.000000\nmean   42.150538   119.419490         4.142857\nstd     8.713990   172.125578         3.945505\nmin    27.000000     0.990000         1.000000\n25%    35.000000    64.500000         3.000000\n50%    41.000000    77.000000         3.000000\n75%    49.000000    93.062500         4.000000\nmax    68.000000   999.990000        25.000000\n"}],"execution_count":19},{"id":"7eb32ef8-2f7b-4867-83a5-8e5ed543dfdd","cell_type":"code","source":"# 3. Report rows and columns\nprint(f\"\\nTotal rows: {df.shape[0]}\")\nprint(f\"Total columns: {df.shape[1]}\")\n","metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"\nTotal rows: 106\nTotal columns: 10\n"}],"execution_count":20},{"id":"f1d9a991-8f70-4493-be77-c4c0ca0d3eb0","cell_type":"code","source":"# 4. Identify data types\nprint(\"\\nData types for each column:\")\nprint(df.dtypes)","metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"\nData types for each column:\ncustomer_id            object\nname                   object\nemail                  object\nage                   float64\nlocation               object\njoin_date              object\nlast_purchase_date     object\norder_total           float64\nitems_purchased       float64\npreferred_category     object\ndtype: object\n"}],"execution_count":21},{"id":"d14691cf-a6f0-4910-956f-484428bfb16e","cell_type":"code","source":"# Part 2: Handling Missing Values\n# 1. Check for missing values\nprint(\"\\nMissing values count:\")\nprint(df.isnull().sum())\n# Create a copy of the dataframe for cleaning\ndf_clean = df.copy()\n\n","metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"\nMissing values count:\ncustomer_id            0\nname                   0\nemail                  0\nage                   13\nlocation               0\njoin_date              0\nlast_purchase_date     8\norder_total            8\nitems_purchased        8\npreferred_category     3\ndtype: int64\n"}],"execution_count":22},{"id":"c709dad7-45f1-4153-9b0e-d7e237fff9cc","cell_type":"code","source":"# 2. Fill missing ages with the median age\nmedian_age = df_clean['age'].median()\ndf_clean['age'] = df_clean['age'].fillna(median_age)\nprint(f\"\\nMedian age used for imputation: {median_age}\")","metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"\nMedian age used for imputation: 41.0\n"}],"execution_count":23},{"id":"a67d6261-86b2-481c-9334-6930ea9f235c","cell_type":"code","source":"# 3. Fill missing last_purchase_date with join_date\n# For rows with missing last_purchase_date, use join_date (without date conversion)\nmask = df_clean['last_purchase_date'].isna()\ndf_clean.loc[mask, 'last_purchase_date'] = df_clean.loc[mask, 'join_date']","metadata":{"trusted":true},"outputs":[],"execution_count":24},{"id":"72e4b899-36f8-4fdb-98c2-8ee6798336c9","cell_type":"code","source":"# 4. Fill missing order_total with 0\ndf_clean['order_total'] = df_clean['order_total'].fillna(0)\n\n# Fill missing items_purchased with 0 (consistent with order_total = 0)\ndf_clean['items_purchased'] = df_clean['items_purchased'].fillna(0)\n","metadata":{"trusted":true},"outputs":[],"execution_count":25},{"id":"fcf9b507-b25a-43bc-9824-649b2933c9be","cell_type":"code","source":"# 5. Fill missing preferred_category with \"Unknown\"\ndf_clean['preferred_category'] = df_clean['preferred_category'].fillna(\"Unknown\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":26},{"id":"96c4834b-6104-4e04-9c86-32f579a31232","cell_type":"code","source":"# Check missing values again to verify\nprint(\"\\nMissing values after imputation:\")\nprint(df_clean.isnull().sum())","metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"\nMissing values after imputation:\ncustomer_id           0\nname                  0\nemail                 0\nage                   0\nlocation              0\njoin_date             0\nlast_purchase_date    0\norder_total           0\nitems_purchased       0\npreferred_category    0\ndtype: int64\n"}],"execution_count":27},{"id":"04c4b243-7f1f-4832-b388-5d65e7377dbb","cell_type":"code","source":"# Part 3: Removing Duplicates\n# 1. Check for duplicate rows\nduplicate_rows = df_clean.duplicated().sum()\nprint(f\"\\nNumber of duplicate rows: {duplicate_rows}\")","metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"\nNumber of duplicate rows: 3\n"}],"execution_count":28},{"id":"ff9b9825-7560-49d1-9ea4-ce9ee2f3c542","cell_type":"code","source":"# 2. Check for duplicate customer IDs\nduplicate_ids = df_clean['customer_id'].duplicated().sum()\nprint(f\"Number of duplicate customer IDs: {duplicate_ids}\")","metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"Number of duplicate customer IDs: 6\n"}],"execution_count":29},{"id":"fa3c4d3e-eeae-4316-8644-260d94f3ebca","cell_type":"code","source":"# 3. Keep only the row with the most recent purchase date for each customer ID\n# The naive approach to sorting dates as strings works in this case since they are all in the same format\n# Note: This would not work correctly if dates had different formats\ndf_clean = df_clean.sort_values(['customer_id', 'last_purchase_date'], ascending=[True, False])\n\n# Drop duplicates, keeping the first occurrence (most recent purchase)\ndf_clean = df_clean.drop_duplicates(subset='customer_id', keep='first')","metadata":{"trusted":true},"outputs":[],"execution_count":30},{"id":"349aa4fb-9300-4054-a8ae-96088c53a128","cell_type":"code","source":"# Verify duplicate removal\nprint(f\"\\nRows after removing duplicates: {len(df_clean)}\")\nprint(f\"Duplicate customer IDs after cleaning: {df_clean['customer_id'].duplicated().sum()}\")\n","metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"\nRows after removing duplicates: 100\nDuplicate customer IDs after cleaning: 0\n"}],"execution_count":31},{"id":"f27a6cce-bdb3-40dd-98f4-8ec16f0bce7c","cell_type":"code","source":"# Display the first few rows of the cleaned dataset\nprint(\"\\nFirst 5 rows of cleaned dataset:\")\nprint(df_clean.head())","metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"\nFirst 5 rows of cleaned dataset:\n   customer_id             name                       email   age  \\\n10    CUST0001       John Smith        john.smith@gmail.com  32.0   \n1     CUST0002     Mary Johnson      mary.johnson@yahoo.com  41.0   \n2     CUST0003  Robert Williams      r.williams@hotmail.com  45.0   \n3     CUST0004   jennifer Brown  jennifer.brown@outlook.com  29.0   \n4     CUST0005   MICHAEL Garcia    michael.garcia@gmail.com  68.0   \n\n       location   join_date last_purchase_date  order_total  items_purchased  \\\n10     New York  2023-06-15         09/05/2024       110.25              4.0   \n1   Los Angeles  2023-08-22         09/15/2024        64.50              2.0   \n2       Chicago  2022-11-30         01/22/2025       125.75              5.0   \n3           NYC  2024-01-18         2024-01-18         0.00              0.0   \n4       Houston  2023-04-07         05/30/2024        42.99              2.0   \n\n   preferred_category  \n10        Electronics  \n1            Clothing  \n2               Books  \n3              Beauty  \n4      home & kitchen  \n"}],"execution_count":32},{"id":"7dfffe45-f741-496a-be7f-dfcb412c9bb2","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}